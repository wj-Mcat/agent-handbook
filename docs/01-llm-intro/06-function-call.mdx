---
title: "Function Call 技术详解"
---


## 一：Function Call 介绍
随着ChatGPT等通用大模型的出现，它们可以生成令人惊叹的自然语言，使得机器能够更好地理解和回应人类的需求，但在特定领域的任务上仅靠通用问答是无法满足日常工作需要。随着OpenAI推出了Function Call功能，工具调用能力越来越作为开源模型的标配。

那什么是 FunctionCall 呢？顾名思义就是大模型能够判断应该调用哪个Function（API、Method）以及对应的参数，这个极大程度上提升了大模型在特定领域上的知识能力，弥补大模型能力上的不足，比如以下例子：

1. 现在北京时间是什么时候？
2. 帮我查一下北京现在的天气？帮我查一下昨天百度股票收盘价是多少？
3. 在机器空闲的时间请帮我跑一下 LLama 的 CE，并把报告发到飞书群（群号：12345678）中，并艾特 XXX 注意消息内容。
以上例子都是真实能够实现的例子，也是现实生活中接触最多最有价值的例子。

### 1.1 原理

FunctionCall 会根据用户的 query 判断是否要调用预定义的函数、如何编排这些函数的调用、如何抽取函数之间的输入参数，整体功能介绍图如下所示：

![](./imgs/function-calling-flow.png)

根据上图可以看出，一个完整的FunctionCall 调用的流程当中需要有以下步骤：
1. LLM 根据用户的 query 来判断：要调用哪个工具（find_course）以及工具的入参（skill=beginner, product=azure）。
2. 调用并执行该工具（find_course）获得输出（AI-900）
3. 将用户对话历史和工具调用信息和工具返回结果等关键信息输入给 LLM，得到最终回复结果（I would recommend AI-900）。

当然为了实现这些功能，肯定是需要从训练数据上做一些处理的，这个在下面的章节中会介绍。

基于 OpenAI SDK FunctionCall 的调用示例如下所示：
```python
response = client.chat.completions.create(
    model=deployment,    
    messages=messages,    
    functions=functions,    # 工具定义信息
    function_call="auto"    # 自动调用某工具
)
print(response.choices[0].message)    
```
如果调用了某工具信息，此时返回的信息如下所示：
```json
{
  "role": "assistant",
  "function_call": {
    "name": "search_courses",
    "arguments": "{\n  \"role\": \"student\",\n  \"product\": \"Azure\",\n  \"level\": \"beginner\"\n}"
  }
}
```
代码摘自：Integrating with function calling 

### 1.2 类型

![](./imgs/function-calling-ravenv2.PNG)

> 图片来自于：https://nexusflow.ai/blogs/ravenv2

从 Function Call 如何编排的角度出发，其类别主要分为四类：
- Single Function：每次只执行一个方法，这是最简单的情况，并且开源 function call 的数据大部分都是这种情况。
- Parallel Functions：可并行执行某些函数，从而减少执行多个函数整体的执行时间。
- Nested Functions：嵌套函数，某个函数依赖某些函数执行的结果。
- DAG Functions：拓扑图结构的函数，符合真实场景下的执行结果。
  - An LLM Compiler for Parallel Function Calling 提出将 Nested Function 和 Parallel Functions 编译成一个拓扑结构的依赖关系
  ![](./imgs/function-calling-parallel.png)
  - 观点：在当前看来，大模型需要根据工具的返回结果来判断接下来要调用的工具类型和参数，直接一下子所有的执行路径都给规划出来，可能不太恰当。
  - 创新点：
    - 可以对出错的 node 进行反思

### 1.3 开源模型对于 Function Call 的支持情况

以下判断是根据官方文档描述所得，和客观真实数据或许有一定的偏差，

| 模型名称                                      	| 类型        	|
|-----------------------------------------------	|-------------	|
| ChatGLM3                                      	| Single FC   	|
| QWen2                                         	| Single FC   	|
| Trelis/Llama-2-7b-chat-hf-function-calling-v2 	| Parallel FC 	|
| Nexusflow/NexusRaven-V2-13B                   	| Parallel FC 	|


### 1.4 使用场景

Function Call 到底有哪些应用场景呢？

- **Conversational Agent**：用于创建复杂的聊天机器人，通过调用外部API或外部知识库并提供更相关和有用的知识来辅助回答复杂的问题。
- **NLU**：它可以将自然语言转换为结构化JSON数据，从文本中提取结构化数据，并执行命名实体识别、情感分析和关键字提取等任务。
- **Math Problem Solving**：可用于定义自定义函数，以解决需要多个步骤和不同类型的高级计算的复杂数学问题。
- **API Integration**：它可以用于有效地将LLM与外部API集成，以获取数据或根据输入执行操作。这可能有助于建立QA系统或创造性助理。一般来说，函数调用可以将自然语言转换为有效的API调用。
- **Information Extraction**：函数调用可有效地用于从给定的输入中提取特定信息，例如从文章中检索相关的新闻报道或引用。


### 1.5 示例代码

以下是使用基于 FunctionCall 的示例代码：

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # 请填写您自己的APIKey
response = client.chat.completions.create(
    model="glm-4-alltools",  # 填写需要调用的模型名称
    messages=[
        {
            "role": "user",
            "content":[
                {
                    "type":"text",
                    "text":"帮我查询2018年至2024年，每年五一假期全国旅游出行数据，并绘制成柱状图展示数据趋势。"
                }
            ]
        }
    ],
    stream=True,
    tools=[
    {
        "type": "function",
        "function": {
            "name": "get_tourist_data_by_year",
            "description": "用于查询每一年的全国出行数据，输入年份范围(from_year,to_year)，返回对应的出行数据，包括总出行人次、分交通方式的人次等。",
            "parameters": {
                "type": "object",
                "properties": {
                    "type": {
                        "description": "交通方式，默认为by_all，火车=by_train，飞机=by_plane，自驾=by_car",
                        "type": "string"
                    },
                    "from_year": {
                        "description": "开始年份，格式为yyyy",
                        "type": "string"
                    },
                    "to_year": {
                        "description": "结束年份，格式为yyyy",
                        "type": "string"
                    }
                },
                "required": ["from_year","to_year"]
            }
        }
      },
      {
        "type": "code_interpreter"
      }
    ]
)

for chunk in response:
    print(chunk)
```

该工具生成的结果是：

```python
ChatCompletionChunk(
    id="cdaad83d-8970-4866-951f-3849de03f85b",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content=None,
                role="assistant",
                tool_calls=[
                    ChoiceDeltaToolCall(
                        index=None,
                        id="call_X2__H_xN3LmUMaxb79gxV",
                        function=ChoiceDeltaToolCallFunction(
                            arguments='{"from_year":"2018"," to_year":"2024"," type":"by_all"}',
                            name="get_tourist_data_by_year",
                        ),
                        type="function",
                    )
                ],
            ),
            finish_reason="tool_calls",
            index=0,
        )
    ],
    created=1719801738,
    model="glm-4-alltools",
    usage=CompletionUsage(prompt_tokens=438, completion_tokens=48, total_tokens=486),
    extra_json=None,
    status="requires_action",
)
```

以上结果包含了调用的工具名称、工具的输入参数，此时开发者需要调用本地的 get_tourist_data_by_year 工具，并（假设）得到结果： [100,100,200,200,300,400]，此时你需要将结果再次提交给模型来得到最终的润色结果，示例代码如下所示：
