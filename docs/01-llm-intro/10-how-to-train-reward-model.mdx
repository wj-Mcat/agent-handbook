---
title: "Reward Model"
---


## 训练

RLHF 中需要从外界获取到 human-feedback 的反馈进而更新模型参数，而此类反馈通常来源于一个 Reward Model。

### 数据搜集


